{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JupyterHub Notebook\n",
    "\n",
    "### This notebook server is hosted on the OpenShift platform which provides a separate server for each individual user. The platform takes care of the provisioning of the server and allocating related to storage.\n",
    "\n",
    "### First, install and import required libraries and watermark our file - to show what libraries and versions we're using. Then define utility functions to integrate with our Object storage and _Verta_ visualisation server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dill\n",
    "\n",
    "import verta.integrations.sklearn\n",
    "from alibi.explainers import AnchorTabular\n",
    "# os.environ[\"MODIN_ENGINE\"] = \"ray\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "# import modin.pandas as pd\n",
    "from datetime import datetime\n",
    "import watermark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from minio import Minio\n",
    "from verta import Client\n",
    "from minio.error import ResponseError\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# import tools as tools\n",
    "%matplotlib inline\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%watermark -n -v -m -g -iv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this next section, on the third line, change experiment_name by appending your username to _customerchurn_, e.g., if your username is user1: \n",
    "#### experiment_name = \"customerchurnuser1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dateTimeObj = datetime.now()\n",
    "timestampStr = dateTimeObj.strftime(\"%d%Y%H%M%S%f\")\n",
    "experiment_name = \"customerchurnuser29\"\n",
    "experiment_id = experiment_name + timestampStr\n",
    "\n",
    "\n",
    "def get_s3_server():\n",
    "    minioClient = Minio('minio-ml-workshop:9000',\n",
    "                    access_key='minio',\n",
    "                    secret_key='minio123',\n",
    "                    secure=False)\n",
    "\n",
    "    return minioClient\n",
    "\n",
    "def get_verta():\n",
    "    client = Client(\"http://172.30.21.193:3000\")\n",
    "    return client\n",
    "\n",
    "def get_meta_store():\n",
    "    client = get_verta()\n",
    "    proj = client.set_project(\"ml-workshop\")\n",
    "    client.set_experiment(experiment_name)\n",
    "    run = client.set_experiment_run(experiment_id)\n",
    "    return run\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this next section, on the second line, insert the value you retrieved from Minio object storage earlier - representing the fully qualified name of your csv file in Minio. This is the file pushed by the data engineer in the format: full_data_csv{USERNAME}/{FILENAME}.csv. \n",
    "#### In my case this value is: full_data_csvuser29/part-00000-59149e08-583c-46a5-bfa0-0b3abecbf1a3-c000.csv (yours will be different)\n",
    "### We refer to this fully qualified name in the Github instructions as CSV-FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "minioClient = get_s3_server()\n",
    "data_file = minioClient.fget_object(\"data\", \"full_data_csvuser29/part-00000-b6e27ca2-1458-4b44-ba29-b88aa9e90186-c000.csv\", \"/tmp/data.csv\")\n",
    "data_file_version = data_file.version_id\n",
    "data = pd.read_csv('/tmp/data.csv')\n",
    "data = data.dropna(axis=0, subset=['Churn'])\n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Convert binary variable into numeric so plotting is easier. We need to later take mean\n",
    "data['Churn'] = data['Churn'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.replace(\" \", np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data['TotalCharges'] = pd.to_numeric(data['TotalCharges'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mean = data['TotalCharges'].mean()\n",
    "data.fillna(mean, inplace=True)\n",
    "# Now we know that total charges has nan values\n",
    "data.isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "import joblib\n",
    "\n",
    "names = ['gender', 'Partner', 'Dependents', 'Premium', 'HomeEquityLoans', 'MoneyMarketAccount', 'PaperlessBilling']\n",
    "\n",
    "\n",
    "# for column in names:\n",
    "#     labelencoder(column)\n",
    "data_enc = data\n",
    "data_enc = data_enc.drop(['Churn', 'customerID'], axis=1)\n",
    "data_enc.head(1)\n",
    "enc = ce.ordinal.OrdinalEncoder(cols=names)\n",
    "enc.fit(data_enc)\n",
    "joblib.dump(enc, 'CustomerChurnOrdinalEncoder.pkl')\n",
    "labelled_set = enc.transform(data_enc)\n",
    "labelled_set.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "names = ['RelationshipManager', 'PrimaryChannel', 'CreditRating', 'AccountType', 'HasCreditCard', 'DebitCard',\n",
    "         'IncomeProtection', 'WealthManagement']\n",
    "\n",
    "\n",
    "ohe = ce.OneHotEncoder(cols=names)\n",
    "data_ohe = data\n",
    "data_ohe = data_ohe.drop(['Churn', 'customerID'], axis=1)\n",
    "data_ohe.head(1)\n",
    "ohe.fit(data_ohe)\n",
    "joblib.dump(ohe, 'CustomerChurnOneHotEncoder.pkl')\n",
    "final_set = ohe.transform(labelled_set)\n",
    "final_set.tail(5)\n",
    "labelled_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = data['Churn']\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_set, labels, test_size=0.2)\n",
    "print ('Training Data Shape',X_train.shape, y_train.shape)\n",
    "print ('Testing Data Shape',X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "Y = data['Churn']\n",
    "X = final_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this next section, we define the method train_and_save_model() where we train and then push our model to Verta - for visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def train_and_save_model():\n",
    "    kfold = KFold(n_splits = 3)\n",
    "    # model = DecisionTreeRegressor(max_depth=5, criterion='mse',min_samples_leaf = 3 ,min_samples_split = 10)\n",
    "    model = DecisionTreeClassifier()\n",
    "    store = get_meta_store()\n",
    "    model = model.fit(X_train, y_train, run=store)\n",
    "    joblib.dump(model, 'CustomerChurnPredictor.sav')\n",
    "    results = model_selection.cross_val_score(model,X,Y,cv = kfold)\n",
    "    print(results)\n",
    "    print('Accuracy',results.mean()*100)\n",
    "\n",
    "    store.log_model(model, overwrite=True)\n",
    "    store.log_metric('Accuracy',results.mean()*100)\n",
    "    store.log_tag(\"DecisionTreeClassifier\")\n",
    "    store.log_attribute(\"data_file_location\", \"data/full_data_csv/a.csv\")\n",
    "    store.log_attribute(\"data_file_version\", data_file_version)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this next section, we define the method explain_model(), where we make available an *_explanation_* of the reasons the model made the decisions it did. This is very useful for auditing purposes as well as for the Application development consumers of the model - who can optionally expand and utilise these reasons for their purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from alibi.utils.data import gen_category_map\n",
    "\n",
    "def explain_model(model, X_train, X_test_record):\n",
    "    fnames = X_train.columns.tolist()\n",
    "    predict_fn = lambda x: model.predict_proba(x)\n",
    "    explainer = AnchorTabular(predict_fn, fnames)\n",
    "    explainer = explainer.fit(X_train.values, disc_perc=[25, 50, 75])\n",
    "    explanation = explainer.explain(X_test_record.values[0])\n",
    "    print('Anchor: %s' % explanation['anchor'])\n",
    "    print('Precision: %.2f' % explanation['precision'])\n",
    "    print('Coverage: %.2f' % explanation['coverage'])\n",
    "    return explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = train_and_save_model()\n",
    "# explainer = explain_model(model, X_train, X_test)\n",
    "# with open(\"CustomerChurnPredictorAlibi.dill\", \"wb\") as x_f:\n",
    "#     dill.dump(explainer, x_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "minioClient = get_s3_server()\n",
    "minioClient.fput_object(bucket_name='models', object_name=experiment_id  +'/CustomerChurnPredictor.sav' , file_path='./CustomerChurnPredictor.sav')\n",
    "# minioClient.fput_object(bucket_name='models', object_name=experiment_id  +'/CustomerChurnPredictorAlibi.dill' , file_path='./CustomerChurnPredictorAlibi.dill')\n",
    "minioClient.fput_object(bucket_name='models', object_name=experiment_id  +'/CustomerChurnOrdinalEncoder.pkl' , file_path='./CustomerChurnOrdinalEncoder.pkl')\n",
    "minioClient.fput_object(bucket_name='models', object_name=experiment_id  +'/CustomerChurnOneHotEncoder.pkl' , file_path='./CustomerChurnOneHotEncoder.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Notebook complete')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "545e036c4b32438aced1f6b3c8d38ca151d9c36189e05839cb0aa568fda70ddd"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
